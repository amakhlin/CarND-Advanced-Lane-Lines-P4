{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_camera_calibration(path='camera_cal/calibration*.jpg', show=False, save_path=None):\n",
    "\n",
    "    # prepare object points\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(path)\n",
    "\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for i, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            \n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "\n",
    "            if save_path is not None:\n",
    "                cv2.imwrite(save_path + 'chess_corners{}.jpg'.format(i),img)\n",
    "\n",
    "            if show is True:\n",
    "                cv2.imshow('img',img)\n",
    "                cv2.waitKey(500)\n",
    "    \n",
    "    if show is True:\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "        \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtx, dist = get_camera_calibration(show=False, save_path='output_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undistort_img(img, mtx, dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def udistort_images(mtx, dist, path='camera_cal/calibration*.jpg', save_path=None):\n",
    "    images = glob.glob(path)\n",
    "        \n",
    "    for i, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        img = undistort_img(img, mtx, dist)\n",
    "        if save_path is not None:\n",
    "            cv2.imwrite(save_path + 'test_undist{}.jpg'.format(i),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "udistort_images(mtx, dist, path='test_images/*.jpg', save_path='test_images_undist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_as(fname, dest_path, suffix):\n",
    "    # remove leading /\n",
    "    fname = fname.split('/')\n",
    "    # add suffix. before the .\n",
    "    fname = fname[-1].replace('.', '_' + suffix + '.')\n",
    "    \n",
    "    return dest_path + fname  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    \n",
    "    h,w = img.shape[0], img.shape[1]\n",
    "        \n",
    "    vertices = np.array([[[int(0.15*w),int(.95*h)], # bot left\n",
    "                          [int(.45*w),int(.58*h)],  # top left\n",
    "                          [int(.55*w),int(.58*h)],  # top right\n",
    "                          [int(.9*w),int(.95*h)]]],# bot right\n",
    "                            dtype=np.int32 )\n",
    "    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 255\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh1(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 255\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sobel\n",
    "# Define a function that takes an image, gradient orientation,\n",
    "# and threshold min / max values.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 255\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that thresholds the S-channel of HLS\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 255\n",
    "    #return binary_output\n",
    "    #print(binary_output)\n",
    "    return binary_output\n",
    "    #return s_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def try_threshold(path):\n",
    "    images = glob.glob(path)\n",
    "    \n",
    "    #plt.subplot(len(images)//2, 2)\n",
    "    #f= plt.subplots(len(images)//2, 2, figsize=(24, 9))\n",
    "    #f.tight_layout()\n",
    "    plt.figure(figsize=(8,10), tight_layout=True)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        #out = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        s_binary = hls_select(img, thresh=(180,255))\n",
    "        sxbinary = abs_sobel_thresh(img, orient='x', thresh_min=30, thresh_max=100)\n",
    "        #sxbinary = dir_threshold(img, thresh=(45./180.*np.pi, 60./180.*np.pi))\n",
    "        \n",
    "        combined_binary = np.zeros_like(s_binary)\n",
    "        combined_binary[(s_binary == 255) | (sxbinary == 255)] = 255\n",
    "            \n",
    "        color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "        \n",
    "        #out = region_of_interest(color_binary)\n",
    "        out = region_of_interest(combined_binary)\n",
    "        \n",
    "        #out = dir_threshold(img, thresh=(45./180.*np.pi, 60./180.*np.pi))\n",
    "        #out = mag_thresh1(img, mag_thresh=(15,100))\n",
    "        #cv2.imshow('img'+str(i),out)\n",
    "        \n",
    "        ax = plt.subplot(len(images)//2, 2, i+1)\n",
    "        ax.axis('off')\n",
    "        plt.imshow(out, cmap='gray')\n",
    "        #plt.imshow(out)\n",
    "        #cv2.waitKey(1000)\n",
    "    \n",
    "    #print(img.shape)\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try_threshold('test_images_undist/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform(img_shape):\n",
    "    \n",
    "    h,w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    top_most = 460\n",
    "    offset = 50\n",
    "    \n",
    "    src = np.float32(\n",
    "        [[579, top_most],\n",
    "         [203, h],\n",
    "         [1127, h],\n",
    "         [704, top_most]])\n",
    "\n",
    "    dst = np.float32(\n",
    "        [[320+offset, 0],\n",
    "         [320+offset, h],\n",
    "         [960-offset, h],\n",
    "         [960-offset, 0]])\n",
    "    \n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    return M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M, Minv = get_perspective_transform((720,1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(img, M):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    return cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1afcdc6a0>"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('test_images_undist/test_undist0.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#img = region_of_interest(img)\n",
    "plt.figure(figsize=(8,10), tight_layout=True)\n",
    "plt.axis('off')\n",
    "#plt.imshow(img)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "#plt.plot(src,'r.')\n",
    "plt.subplot(1, 2, 2)\n",
    "warped = warp(img, M)\n",
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_transform(path):\n",
    "    images = glob.glob(path)\n",
    "    \n",
    "    plt.figure(figsize=(8,10), tight_layout=True)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        out = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        out = warp(out, M)\n",
    "        ax = plt.subplot(len(images)//2, 2, i+1)\n",
    "        ax.axis('off')\n",
    "        plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_transform('test_images_undist/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(fname):\n",
    "    img = cv2.imread(fname)\n",
    "    s_binary = hls_select(img, thresh=(170,255)) #175,255\n",
    "    sxbinary = abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=150) #30/100\n",
    "    combined_binary = np.zeros_like(s_binary)\n",
    "    combined_binary[(s_binary == 255) | (sxbinary == 255)] = 255\n",
    "    out = region_of_interest(combined_binary)\n",
    "    out = warp(out, M)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_and_grandient_threshold(img):\n",
    "    s_binary = hls_select(img, thresh=(170,255))\n",
    "    sxbinary = abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=150)\n",
    "    combined_binary = np.zeros_like(s_binary)\n",
    "    combined_binary[(s_binary == 255) | (sxbinary == 255)] = 255\n",
    "    out = region_of_interest(combined_binary)\n",
    "    #out = warp(out, M)\n",
    "    \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_pipeline(path):\n",
    "    images = glob.glob(path)\n",
    "    \n",
    "    plt.figure(figsize=(8,10), tight_layout=True)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, fname in enumerate(images):\n",
    "        out = pipeline(fname)\n",
    "        plt.subplot(len(images)//2, 2, i+1)\n",
    "        plt.imshow(out, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_pipeline('test_images_undist/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = pipeline('test_images_undist/test_undist6.jpg')\n",
    "out_img = np.dstack((img, img, img))*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1be53eb38>"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,10), tight_layout=True)\n",
    "#histogram = np.sum(img[int(img.shape[0]/2):,:], axis=0)\n",
    "#plt.plot(histogram)\n",
    "#plt.imshow(img, cmap='gray')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_baseline_x(img, lane='left'):\n",
    "    # histogram for lower half\n",
    "    histogram = np.sum(img[np.int(img.shape[0]/2):,:], axis=0)\n",
    "    \n",
    "    # find midpoint along x\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    \n",
    "    if lane is 'left':\n",
    "        x_base = np.argmax(histogram[:midpoint])\n",
    "    else:\n",
    "        x_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    return x_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_and_loc(x, y):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    y_eval_m = 720*ym_per_pix\n",
    "    x = x*xm_per_pix\n",
    "    y = y*ym_per_pix\n",
    "    \n",
    "    fit = np.polyfit(y, x, 2)\n",
    "    \n",
    "    r = ((1 + (2.*fit[0]*y_eval_m + fit[1])**2)**1.5) / np.absolute(2*fit[0])\n",
    "    \n",
    "    # evaluate fit at the bottom of image\n",
    "    loc = fit[0]*y_eval_m**2 + fit[1]*y_eval_m + fit[2]\n",
    "    \n",
    "    center_of_image_m = (1280. / 2.) * xm_per_pix\n",
    "    \n",
    "    loc -= center_of_image_m\n",
    "    \n",
    "    return r, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_x_base = find_baseline_x(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "right_x_base = find_baseline_x(img, lane='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window_search(img, x_base, debug=False, out_img=None):\n",
    "    \n",
    "    # set parameters\n",
    "    # number of sliding windows (height dir)\n",
    "    nwindows = 9\n",
    "    \n",
    "    # width of the sliding search window is +/- margin\n",
    "    margin = 100\n",
    "    # recenter next window if at least this many points were found\n",
    "    minpix = 50\n",
    "    \n",
    "    #if debug is True:\n",
    "    #    out_img = np.dstack((img, img, img))*255\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    x_current = x_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        \n",
    "        win_x_low = x_current - margin\n",
    "        win_x_high = x_current + margin\n",
    "        \n",
    "        if debug is True and out_img is not None:\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_x_low,win_y_low),(win_x_high,win_y_high),(0,255,0), 2)\n",
    "            \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_inds = ((nonzeroy >= win_y_low) &\n",
    "                     (nonzeroy < win_y_high) & \n",
    "                     (nonzerox >= win_x_low) & \n",
    "                     (nonzerox < win_x_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        lane_inds.append(good_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_inds) > minpix:\n",
    "            x_current = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    lane_inds = np.concatenate(lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    x = nonzerox[lane_inds]\n",
    "    y = nonzeroy[lane_inds] \n",
    "    \n",
    "    if debug is True and out_img is not None:\n",
    "        out_img[nonzeroy[lane_inds], nonzerox[lane_inds]] = [255, 0, 0]\n",
    "\n",
    "\n",
    "    # Fit a second order polynomial\n",
    "    fit = np.polyfit(y, x, 2)\n",
    "    \n",
    "    # find ROC and lane location at bottom of image\n",
    "    r, loc = roc_and_loc(x, y)\n",
    "    \n",
    "    #if debug is True:\n",
    "    #    plt.figure(figsize=(8,10), tight_layout=True)\n",
    "    #    plt.imshow(out_img)\n",
    "\n",
    "    return fit, r, loc, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487.674940374\n",
      "-1.43133753413\n"
     ]
    }
   ],
   "source": [
    "fit_left, r_left, loc_left, out_img = sliding_window_search(img, left_x_base, debug=True, out_img=out_img)\n",
    "print(r_left)\n",
    "print(loc_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161.85361622\n",
      "1.54026468265\n"
     ]
    }
   ],
   "source": [
    "fit_right, r_right, loc_right, out_img = sliding_window_search(img, right_x_base, debug=True, out_img=out_img)\n",
    "print(r_right)\n",
    "print(loc_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108927148519\n"
     ]
    }
   ],
   "source": [
    "print(loc_left + loc_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_fit(img, left_fit, right_fit, out_img, single_image=False):\n",
    "    # Generate x and y values for plotting\n",
    "    \n",
    "    if single_image:\n",
    "        plt.figure(figsize=(8,10), tight_layout=True)\n",
    "    \n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_fit(img, fit_left, fit_right, out_img, single_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_fit_batch(path):\n",
    "    images = glob.glob(path)\n",
    "    \n",
    "    plt.figure(figsize=(8,10), tight_layout=True)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for i, fname in enumerate(images):\n",
    "        img = pipeline(fname)\n",
    "        out_img = np.dstack((img, img, img))*255\n",
    "        \n",
    "        plt.subplot(len(images)//2, 2, i+1)\n",
    "        \n",
    "        left_x_base = find_baseline_x(img, lane='left')\n",
    "        right_x_base = find_baseline_x(img, lane='right')\n",
    "        \n",
    "        fit_left, out_img = sliding_window_search(img, left_x_base, debug=True, out_img=out_img)\n",
    "        fit_right, out_img = sliding_window_search(img, right_x_base, debug=True, out_img=out_img)\n",
    "        \n",
    "        visualize_fit(img, fit_left, fit_right, out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_fit_batch('test_images_undist/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_fit_search(img, fit, debug=False, out_img=None):\n",
    "    # search based on fit from pervious images\n",
    "    \n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    margin = 100\n",
    "    \n",
    "    lane_inds = ((nonzerox > (fit[0]*(nonzeroy**2) + fit[1]*nonzeroy + fit[2] - margin)) &\n",
    "                 (nonzerox < (fit[0]*(nonzeroy**2) + fit[1]*nonzeroy + fit[2] + margin))) \n",
    "\n",
    "    # Extract line pixel positions\n",
    "    x = nonzerox[lane_inds]\n",
    "    y = nonzeroy[lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial\n",
    "    fit = np.polyfit(y, x, 2)\n",
    "    \n",
    "    if debug is True and out_img is not None:\n",
    "        out_img[nonzeroy[lane_inds], nonzerox[lane_inds]] = [255, 0, 0]\n",
    "\n",
    "    return fit, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_img = np.dstack((img, img, img))*255\n",
    "fit_left, out_img = local_fit_search(img, fit_left, debug=True, out_img=out_img)\n",
    "fit_right, out_img = local_fit_search(img, fit_right, debug=True, out_img=out_img)\n",
    "visualize_fit(img, fit_left, fit_right, out_img, single_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_overlay(img, fit_l, fit_r, Minv, r_left, r_right, loc_error):\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(img).astype(np.uint8)\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    left_fitx = fit_l[0]*ploty**2 + fit_l[1]*ploty + fit_l[2]\n",
    "    right_fitx = fit_r[0]*ploty**2 + fit_r[1]*ploty + fit_r[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(result, '{:s}: {:>+5.2f} m'.format('lane centering', loc_error), (450,700), font, 1,(255,255,255),2)\n",
    "    cv2.putText(result, '{:s}: {:+.2f} m'.format('ROC', r_left), (50,700), font, 1,(255,255,255),2)\n",
    "    cv2.putText(result, '{:s}: {:+.2f} m'.format('ROC', r_right), (970,700), font, 1,(255,255,255),2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bea25160>"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,10), tight_layout=True)\n",
    "plt.axis('off')\n",
    "img = cv2.imread('test_images_undist/test_undist6.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bf9f2748>"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_error = loc_left + loc_right\n",
    "result = draw_overlay(img, fit_left, fit_right, Minv, r_left, r_right, loc_error)\n",
    "result = process_image(img)\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.axis('off')\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    # distortion correction\n",
    "    img = undistort_img(img, mtx, dist)\n",
    "    \n",
    "    # color and gradient thresholding\n",
    "    img_th = color_and_grandient_threshold(img)\n",
    "    \n",
    "    # perspective transform\n",
    "    img_th = warp(img_th, M)\n",
    "    \n",
    "    # line identification\n",
    "    left_x_base = find_baseline_x(img_th, lane='left')\n",
    "    right_x_base = find_baseline_x(img_th, lane='right')\n",
    "    \n",
    "    fit_left, r_left, loc_left, _ = sliding_window_search(img_th, left_x_base)\n",
    "    fit_right, r_right, loc_right, _ = sliding_window_search(img_th, right_x_base)\n",
    "    \n",
    "    loc_error = loc_left + loc_right\n",
    "    \n",
    "    # line drawing and perspetive inverse transform\n",
    "    out = draw_overlay(img, fit_left, fit_right, Minv, r_left, r_right, loc_error)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cb821550>"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_video.mp4\n",
      "[MoviePy] Writing video output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [02:59<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_video = 'output_video.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "out_clip = clip.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "out_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
